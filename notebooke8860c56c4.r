{"metadata":{"kernelspec":{"name":"ir","display_name":"R","language":"R"},"language_info":{"name":"R","codemirror_mode":"r","pygments_lexer":"r","mimetype":"text/x-r-source","file_extension":".r","version":"4.0.5"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7746251,"sourceType":"datasetVersion","datasetId":1041311}],"dockerImageVersionId":30618,"isInternetEnabled":true,"language":"r","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This R environment comes with many helpful analytics packages installed\n# It is defined by the kaggle/rstats Docker image: https://github.com/kaggle/docker-rstats\n# For example, here's a helpful package to load\n\nlibrary(tidyverse) # metapackage of all tidyverse packages\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nlist.files(path = \"../input\")\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"051d70d956493feee0c6d64651c6a088724dca2a","_execution_state":"idle"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**From Issue to Action: The Six Data Analysis Phases**\n\n[From Issue to Action: The Six data Analysis Phases](https://www.coursera.org/learn/ask-questions-make-decisions/supplement/Tbsdh/from-issue-to-action-the-six-data-analysis-phases) \n\nThese six steps can help you to break the Data Analysis Process into smaller, manageable parts, which is called structured thinking. \n\nThis process involves four basic activities:\n\n- Recognizing the current problem or situation\n- Organizing available information \n- Revealing gaps and opportunities\n- Identifying your options\n\n---\n\n**Ask**\n\nIt’s impossible to solve a problem if you don’t know what it is. These are some things to consider:\n\n**Define the problem you’re trying to solve**\n- Make sure you fully understand the stakeholder’s expectations\n- Focus on the actual problem and avoid any distractions\n- Collaborate with stakeholders and keep an open line of communication\n- Take a step back and see the whole situation in context\n\n**Questions to ask yourself in this step:**\n\n- What are my stakeholders saying their problems are?\n- Now that I’ve identified the issues, how can I help the stakeholders resolve their questions?\n\n---\n\n\n**Prepare**\n\nYou will decide what data you need to collect in order to answer your questions and how to organize it so that it is useful. \n\n**You might use your business task to decide:** \n\n- What metrics to measure\n- Locate data in your database\n- Create security measures to protect that data\n\n**Questions to ask yourself in this step:** \n- What do I need to figure out how to solve this problem?\n- What research do I need to do?\n\n---\n\n**Process**\n\nClean data is the best data and you will need to clean up your data to get rid of any possible errors, inaccuracies, or inconsistencies. \n\n**This might mean:**\n\n- Using spreadsheet functions to find incorrectly entered data\n- Using SQL functions to check for extra spaces\n- Removing repeated entries\n- Checking as much as possible for bias in the data\n\n**Questions to ask yourself in this step:**\n\n- What data errors or inaccuracies might get in my way of getting the best possible answer to the problem I am trying to solve?\n- How can I clean my data so the information I have is more consistent?\n\n\n---\n\n**Analyze**\n\nYou will want to think analytically about your data. At this stage, you might sort and format your data to make it easier to: \n\n**Perform calculations**\n\n- Combine data from multiple sources\n- Create tables with your results\n\n**Questions to ask yourself in this step:**\n\n- What story is my data telling me?\n- How will my data help me solve this problem?\n- Who needs my company’s product or service? What type of person is most likely to use it?\n\n---\n\n**Share**\n\nEveryone shares their results differently so be sure to summarize your results with clear and enticing visuals of your analysis using data via tools like graphs or dashboards. This is your chance to show the stakeholders you have solved their problem and how you got there. \n\n**Sharing will certainly help your team:** \n\n- Make better decisions\n- Make more informed decisions\n- Lead to stronger outcomes\n- Successfully communicate your findings\n\n**Questions to ask yourself in this step:**\n\n- How can I make what I present to the stakeholders engaging and easy to understand?\n- What would help me understand this if I were the listener?\n\n---\n\n**Act**\n\nYou will take everything you have learned from your data analysis and put it to use. This could mean providing your stakeholders with recommendations based on your findings so they can make data-driven decisions.\n\n**Questions to ask yourself in this step:**\n\nHow can I use the feedback I received during the share phase (step 5) to actually meet the stakeholder’s needs and expectations?","metadata":{"_kg_hide-input":false}},{"cell_type":"markdown","source":"---","metadata":{}},{"cell_type":"markdown","source":"**e.g.**\n\n> [Case Study: New Data Perspectives](https://www.coursera.org/learn/foundations-data/supplement/nhC19/case-study-new-data-perspectives)\n\n---","metadata":{}},{"cell_type":"markdown","source":"# Bellabeat","metadata":{}},{"cell_type":"markdown","source":"---\n[bellabeat R script template](https://docs.google.com/document/d/1gmPCr0zqjOtVK_y_BKsaUItBJHakw9ghB4x7dZYVvvo/template/preview?usp=sharing)\n---","metadata":{"_kg_hide-input":false}},{"cell_type":"code","source":"\n############################\n## Introduction and background ##\n############################\n\n# This is meant to be a sample starter script if you choose to use R \n# for this case study. This is not comprehensive of everything you'll \n# do in the case study, but should be used as a starting point if it is helpful for you.\n\n###########################\n## Upload your CSV files to R ##\n###########################\n\n# Remember to upload your CSV files to your project from the relevant data source:\n# https://www.kaggle.com/arashnic/fitbit\n\n# Remember, there are many different CSV files in the dataset. \n# We have uploaded two CSVs into the project, but you will likely \n# want to use more than just these two CSV files.\n\n################################################\n## Installing and loading common packages and libraries ##\n################################################\n\n# You can always install and load packages along the way as you may \n# discover you need different packages after you start your analysis. \n# If you already have some of these packages installed and loaded, you \n# can skip those ones - or you can choose to run those specific lines of \n#code anyway. It may take a few moments to run.\n\n#Install and load the tidyverse\ninstall.packages('tidyverse')\nlibrary(tidyverse)\n\n#####################\n## Load your CSV files ##\n#####################\n\n# Create a dataframe named 'daily_activity' and read in one \n# of the CSV files from the dataset. Remember, you can name your dataframe \n# something different, and you can also save your CSV file under a different name as well.\n\ndaily_activity <- read.csv(\"dailyActivity_merged.csv\")\n\n\n# Create another dataframe for the sleep data. \nsleep_day <- read.csv(\"sleepDay_merged.csv\")\n\n#########################\n## Explore a few key tables ##\n#########################\n\n# Take a look at the daily_activity data.\n\nhead(daily_activity)\n\n\n# Identify all the columns in the daily_activity data.\ncolnames(daily_activity)\n\n\n# Take a look at the sleep_day data.\n\nhead(sleep_day)\n\n\n# Identify all the columns in the daily_activity data.\n\ncolnames(sleep_day)\n\n\n# Note that both datasets have the 'Id' field - \n# this can be used to merge the datasets.\n\n#####################################\n## Understanding some summary statistics ##\n#####################################\n\n# How many unique participants are there in each dataframe? \n# It looks like there may be more participants in the daily activity \n# dataset than the sleep dataset.\n\nn_distinct(daily_activity$Id)\nn_distinct(sleep_day$Id)\n\n\n# How many observations are there in each dataframe?\n\nnrow(daily_activity)\nnrow(sleep_day)\n\n\n# What are some quick summary statistics we'd want to know about each data frame?\n  \n# For the daily activity dataframe:\ndaily_activity %>%  \n  select(TotalSteps,\n         TotalDistance,\n         SedentaryMinutes) %>%\n  summary()\n\n\n# For the sleep dataframe:\n\nsleep_day %>%  \n  select(TotalSleepRecords,\n         TotalMinutesAsleep,\n         TotalTimeInBed) %>%\n  summary()\n\n\n# What does this tell us about how this sample of people's activities? \n\n##########################\n## Plotting a few explorations ##\n##########################\n\n# What's the relationship between steps taken in a day and sedentary minutes? \n# How could this help inform the customer segments that we can market to? \n# E.g. position this more as a way to get started in walking more? \n# Or to measure steps that you're already taking?\n\nggplot(data=daily_activity, aes(x=TotalSteps, y=SedentaryMinutes)) + geom_point()\n\n\n# What's the relationship between minutes asleep and time in bed? \n# You might expect it to be almost completely linear - are there any unexpected trends?\n  \n\nggplot(data=sleep_day, aes(x=TotalMinutesAsleep, y=TotalTimeInBed)) + geom_point()\n\n\n# What could these trends tell you about how to help market this product? Or areas where you might want to explore further?\n  \n##################################\n## Merging these two datasets together ##\n##################################\n  \ncombined_data <- merge(sleep_day, daily_activity, by=\"Id\")\n\n# Take a look at how many participants are in this data set.\n\n\nn_distinct(combined_data$Id)\n\n\n# Note that there were more participant Ids in the daily activity \n# dataset that have been filtered out using merge. Consider using 'outer_join' \n# to keep those in the dataset. \n\n# Now you can explore some different relationships between activity and sleep as well. \n# For example, do you think participants who sleep more also take more steps or fewer \n# steps per day? Is there a relationship at all? How could these answers help inform \n# the marketing strategy of how you position this new product?\n  \n# This is just one example of how to get started with this data - there are many other \n# files and questions to explore as well!\n\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---","metadata":{}},{"cell_type":"markdown","source":"# Capstone","metadata":{}},{"cell_type":"markdown","source":"**Introduction**.\n\nWelcome to the Bellabeat data analysis case study! In this case study, you will perform many real-world tasks of a junior data analyst. You will imagine you are working for Bellabeat, a high-tech manufacturer of health-focused products for women, and meet different characters and team members. In order to answer the key business questions, you will follow the steps of the\ndata analysis process: **ask, prepare, process, analyze, share,** and **act**. Along the way, the **Case Study Roadmap** tables — including guiding questions and key tasks — will help you stay on the right path.\n\nBy the end of this lesson, you will have a portfolio-ready case study. Download the packet and reference the details of this case study anytime. Then, when you begin your job hunt, your case study will be a tangible way to demonstrate your knowledge and skills to potential employers.\n\n**Scenario**\n\nYou are a junior data analyst working on the marketing analyst team at Bellabeat, a high-tech manufacturer of health-focused products for women. Bellabeat is a successful small company, but they have the potential to become a larger player in the global [smart device](https://en.wikipedia.org/wiki/Smart_device) market. Urška Sršen, cofounder and Chief Creative Officer of Bellabeat, believes that analyzing smart device fitness data could help unlock new growth opportunities for the company. You have been asked to focus on one of Bellabeat’s products and analyze smart device data to gain insight into how consumers are using their smart devices. The insights you discover will then help guide marketing strategy for the company. You will present your analysis to the Bellabeat executive team along with your high-level recommendations for Bellabeat’s marketing strategy.\n\n**Characters and products**\n\n- **Characters**\n\n - **Urška Sršen:** Bellabeat’s cofounder and Chief Creative Officer\n - **Sando Mur:** Mathematician and Bellabeat’s cofounder; key member of the Bellabeat executive team\n - **Bellabeat marketing analytics team:** A team of data analysts responsible for collecting, analyzing, and reporting data that helps guide Bellabeat’s marketing strategy. You joined this team six months ago and have been busy learning about Bellabeat’’s mission and business goals — as well as how you, as a junior data analyst, can help Bellabeat achieve them.\n\n\n- **Products**\n\n - **Bellabeat app:** The Bellabeat app provides users with health data related to their activity, sleep, stress, menstrual cycle, and mindfulness habits. This data can help users better understand their current habits and\nmake healthy decisions. The Bellabeat app connects to their line of smart wellness products.\n - **Leaf:** Bellabeat’s classic wellness tracker can be worn as a bracelet, necklace, or clip. The Leaf tracker connects to the Bellabeat app to track activity, sleep, and stress.\n - **Time:** This wellness watch combines the timeless look of a classic timepiece with smart technology to track user activity, sleep, and stress. The Time watch connects to the Bellabeat app to provide you with insights into your daily wellness.\n - **Spring:** This is a water bottle that tracks daily water intake using smart technology to ensure that you are appropriately hydrated throughout the day. The Spring bottle connects to the Bellabeat app to track your hydration levels.\n - **Bellabeat membership:** Bellabeat also offers a subscription-based membership program for users.Membership gives users 24/7 access to fully personalized guidance on nutrition, activity, sleep, health and beauty, and mindfulness based on their lifestyle and goals.\n\n**About the company**\n\nUrška Sršen and Sando Mur founded Bellabeat, a high-tech company that manufactures health-focused smart products. Sršen used her background as an artist to develop beautifully designed technology that informs and inspires women around the world. Collecting data on activity, sleep, stress, and reproductive health has allowed Bellabeat to empower women with knowledge about their own health and habits. Since it was founded in 2013, Bellabeat has grown rapidly and quickly positioned itself as a tech-driven wellness company for women.\n\nBy 2016, Bellabeat had opened offices around the world and launched multiple products. Bellabeat products became available through a growing number of online retailers in addition to their own e-commerce channel on [their website](https://bellabeat.com/). The company has invested in traditional advertising media, such as radio, out-of-home billboards, print, and television, but focuses on digital marketing extensively. Bellabeat invests year-round in Google Search, maintaining active Facebook and Instagram pages, and consistently engages consumers on Twitter. Additionally, Bellabeat runs video ads on Youtube and display ads on the Google Display Network to support campaigns around key marketing dates.\n\nSršen knows that an analysis of Bellabeat’s available consumer data would reveal more opportunities for growth. She has asked the marketing analytics team to focus on a Bellabeat product and analyze smart device usage data in order to gain insight into how people are already using their smart devices. Then, using this information, she would like high-level recommendations for how these trends can inform Bellabeat marketing strategy.\n\n**Ask**\n\nSršen asks you to analyze smart device usage data in order to gain insight into how consumers use non-Bellabeat smart\ndevices. She then wants you to select one Bellabeat product to apply these insights to in your presentation. These questions\nwill guide your analysis:\n\n1. What are some trends in smart device usage? \n2. How could these trends apply to Bellabeat customers? \n3. How could these trends help influence Bellabeat marketing strategy?\n\n**Deliverables:**\n1. A clear summary of the business task \n2. A description of all data sources used \n3. Documentation of any cleaning or manipulation of data \n4. A summary of your analysis \n5. Supporting visualizations and key findings \n6. Your top high-level content recommendations based on your analysis","metadata":{}},{"cell_type":"markdown","source":"**e.g.**\n\n*Here is a real-life example of how one group of data analysts used the six steps of the data analysis process to improve their workplace and its business processes. Their story involves something called people analytics — also known as human resources analytics or workforce analytics. People analytics is the practice of collecting and analyzing data on the people who make up a company’s workforce in order to gain insights to improve how the company operates.*\n\n*Being a people analyst involves using data analysis to gain insights about employees and how they experience their work lives. The insights are used to define and create a more productive and empowering workplace. This can unlock employee potential, motivate people to perform at their best, and ensure a fair and inclusive company culture.*\n\n*The six steps of the data analysis process that you have been learning in this program are: ask, prepare, process, analyze, share, and act. These six steps apply to any data analysis. Continue reading to learn how a team of people analysts used these six steps to answer a business question.*\n\n*An organization was experiencing a high turnover rate among new hires. Many employees left the company before the end of their first year on the job. The analysts used the data analysis process to answer the following question: how can the organization improve the retention rate for new employees?* \n\n*Here is a break down of what this team did, step by step.*","metadata":{}},{"cell_type":"markdown","source":"# Table of Contents\n- [Introduction](#Introduction)\n- [6 Data Analysis Phases](#6DataAnalysisPhases)\n - [Ask](#Ask)\n - [Prepare](#Prepare)\n - [Process](#Process)\n - [Analyze](#Analyze)\n - [Share](#Share)\n - [Act](#Act)\n- [Appendix](#Appendix)","metadata":{}},{"cell_type":"markdown","source":"---","metadata":{}},{"cell_type":"markdown","source":"# Introduction\nBellabeat is a high-tech company which manufactures health-focused smart products for women. As a junior data analyst, which I have also been a member of the marketing analytics team, I would like to analyze the data of an other-brand smart device to reveal usage habits and patterns which will then support to guide the company's marketing strategy.\n\n*“How do I define success for this project?”*\\\nA successful outcome of this project could be defined with an outcome of non-intuitive insights gained.\n\n---","metadata":{}},{"cell_type":"markdown","source":"# 6DataAnalysisPhases\n [Ask](#Ask) -> [Prepare](#Prepare) -> [Process](#Process) -> [Analyze](#Analyze) -> [Share](#Share) -> [Act](#Act)","metadata":{}},{"cell_type":"markdown","source":"---","metadata":{}},{"cell_type":"markdown","source":"# Ask.\nSršen asks you to analyze smart device usage data in order to gain insight into how consumers use non-Bellabeat smart devices. She then wants you to select one Bellabeat product to apply these insights to in your presentation. These questions will guide your analysis:\n\n1. What are some trends in smart device usage?\n2. How could these trends apply to Bellabeat customers?\n3. How could these trends help influence Bellabeat marketing strategy?\n\n**You will produce a report with the following deliverables:**\n1. A clear summary of the business task\n2. A description of all data sources used\n3. Documentation of any cleaning or manipulation of data\n4. A summary of your analysis\n5. Supporting visualizations and key findings\n6. Your top high-level content recommendations based on your analysis\n\nUse the following Case Study Roadmap as a guide. Note: Completing this case study within a week is a good goal.\n\n**Case Study Roadmap - Ask**\n\n**Guiding questions**\n- What is the problem you are trying to solve?\n- How can your insights drive business decisions?\n\n**Key tasks**\n1. Identify the business task\n2. Consider key stakeholders\n\n**Deliverable**\n\nA clear statement of the business task","metadata":{}},{"cell_type":"markdown","source":"**e.g.**\n\n*First up, the analysts needed to define what the project would look like and what would qualify as a successful result. So, to determine these things, they asked effective questions and collaborated with leaders and managers who were interested in the outcome of their people analysis. These were the kinds of questions they asked:*\n\n*What do you think new employees need to learn to be successful in their first year on the job?*\n\n*Have you gathered data from new employees before? If so, may we have access to the historical data?*\n\n*Do you believe managers with higher retention rates offer new employees something extra or unique?*\n\n*What do you suspect is a leading cause of dissatisfaction among new employees?*\n\n*By what percentage would you like employee retention to increase in the next fiscal year?*","metadata":{}},{"cell_type":"markdown","source":"# Ask\n\n## Business Task\n\nThe business task involves examining usage data from a smart device made by another brand. The goal is to uncover usage patterns and habits, which will subsequently inform Bellabeat’s marketing strategy.\n\nAs historical data of some other-brand fitness tracker will be used during the analysis to understand how these devices are used, we can define the case as a kind of a problem to find patterns.\n\nAs the data already available for analysis is from a wrist-worn tracker device type, my focus will be also on the similar Bellabeat device: **Time**. \n\n**Time** is a fitness watch to track user activity, sleep and stress and I expect that analyzing the available wrist-band usage data will suggest us some patterns and relationships between these records.\n\n## Stakeholders\n\n**Primary stakeholders:**\n*Urška Sršen:* Bellabeat’s cofounder, Chief Creative Officer\n*Sando Mur:* Bellabeat’s cofounder, mathematician, key member of the Bellabeat executive team\n\n**Secondary stakeholders:**\n*Bellabeat marketing analytics team:* A team of data analysts, which acc. to the case I have also been a member of since the last 6 months, working to support the decision process in Bellabeat's marketing strategy by collecting, analyzing, and reporting data. Other data analysts in the team will probably  use the outcomes of my analysis for their own work.\n\n---","metadata":{}},{"cell_type":"markdown","source":"# Prepare.\n\nSršen encourages you to use public data that explores smart device users’ daily habits. She points you to a specific data set:\n\n- [FitBit Fitness Tracker Data](https://www.kaggle.com/datasets/arashnic/fitbit) (CC0: Public Domain, dataset made available through [Mobius](https://www.kaggle.com/arashnic)): This Kaggle data set contains personal fitness tracker from thirty fitbit users. Thirty eligible Fitbit users consented to the submission of personal tracker data, including minute-level output for physical activity, heart rate, and sleep monitoring. It includes information about daily activity, steps, and heart rate that can be used to explore users’ habits.\n\nSršen tells you that this data set might have some limitations, and encourages you to consider adding another data to help address those limitations as you begin to work more with this data.\n\nNow, prepare your data for analysis using the following Case Study Roadmap as a guide:\n\n**Case Study Roadmap - Prepare**\n\n**Guiding questions**\n- Where is your data stored?\n- How is the data organized? Is it in long or wide format?\n- Are there issues with bias or credibility in this data? [Does your data ROCCC?](https://www.coursera.org/learn/data-preparation/lecture/lHirM/what-is-bad-data)\n- How are you addressing licensing, privacy, security, and accessibility?\n- How did you verify the data’s integrity?\n- How does it help you answer your question?\n- Are there any problems with the data?\n\n**Key tasks**\n1. Download data and store it appropriately.\n2. Identify how it’s organized.\n3. Sort and filter the data.\n4. Determine the credibility of the data.\n\n**Deliverable**\n\nA description of all data sources used","metadata":{}},{"cell_type":"markdown","source":"**e.g.**\n\n*Prepare data by collecting and storing the information.*\n\n*It all started with solid preparation. The group built a timeline of three months and decided how they wanted to relay their progress to interested parties. Also during this step, the analysts identified what data they needed to achieve the successful result they identified in the previous step - in this case, the analysts chose to gather the data from an online survey of new employees. These were the things they did to prepare:*\n\n*They developed specific questions to ask about employee satisfaction with different business processes, such as hiring and onboarding, and their overall compensation.*\n\n*They established rules for who would have access to the data collected - in this case, anyone outside the group wouldn't have access to the raw data, but could view summarized or aggregated data. For example, an individual's compensation wouldn't be available, but salary ranges for groups of individuals would be viewable.*\n\n*They finalized what specific information would be gathered, and how best to present the data visually. The analysts brainstormed possible project- and data-related issues and how to avoid them.*","metadata":{}},{"cell_type":"markdown","source":"# Prepare\n\n**Guiding questions**\n\n- Where is your data stored?\n\nThe dataset is available via: [Fitbit Fitness Tracker Data](https://www.kaggle.com/datasets/arashnic/fitbit). \n\n\nThe folder where the zip file was extracted is named with the download date of the data acc. to [ISO 8601](https://en.wikipedia.org/wiki/ISO_8601) standard with a clear definition (**YYYYMMDD_capstoneRawData**). No change on the file names were done. To understand better of the relevant CSV files, an online search revealed the fitabase data dictionary.\n\n- How is the data organized? Is it in long or wide format?\n\nThe dataset consists of 2 main folders: one with different type of records between the dates: 3.12.16 to 4.11.16 and has 11 files in it . The second folder has 18 different files for the dates between 4.12.16 to 5.12.26.\nThe majority of the files are long format. Only the minuteInsenties and sleepInsenties have both data inlong and also wide format.\n\nThe **Kaggle** Data Explorer feature was very useful to make the initial review on the data. No further planned exploration performed before the process phase.\n\n[link](https://www.kaggle.com/datasets/arashnic/fitbit)\n\n* Are there issues with bias or credibility in this data? Does your data **ROCCC?**\n\nAs it will not be possible to gather primary data, we will be using this available secondary data for this study. As we will be using the quantitative data available from sensor records on a tracker, instead of a survey, there is little concern to expect observer bias, excluding maybe manual weight log entries.\n\nThe data has some limitations, but is fine for the scope of this study.\n\nThe dataset is also already structured and seems to be more or less ready to use.\n\n  + **Reliable**: The data is from a research project, which is properly mentioned in the **Kaggle** link. The data has also been used by Kaggle community for projects so far, so there is already up to some degree of confirmation.\n\n  + **Original**: The data is the original data from the research and available to us as secondary data. The data is also anonymized as only User ID's available instead of other defining features.\n\n  + **Comprehensive**: The data is comprehensive, as it includes many different usage info in different activities. As a business of manufacturing products for women, some further details about the demographics of the users would have been useful. Another research on the usage records of the target persona might be considered in the future.\n\n  + **Current**: The data is not very recent, but from 2016. A significant change in general user habits like activity, steps taken during the day or sleep is not expected since then, so the data should be fine to use in this study.\n\n  + **Cited**: The data is cited: [zenodo.org](https://zenodo.org/records/53894#.YMoUpnVKiP9)    \n\n- How are you addressing licensing, privacy, security, and accessibility?\n\nLicencing information about the dataset, which is **CC0**: Public Domain, can be found at [Kaggle](https://www.kaggle.com/datasets/arashnic/fitbit). Further information about the CC0 licence is available also at: [CC0 1.0 Universal (CC0 1.0) Public Domain](https://creativecommons.org/publicdomain/zero/1.0/). With the available information, it is Ok to work on this data. \n\n- How did you verify the data’s integrity?\n\nAt first, **Power Query** was used to make an initial review and to sort and filter the data but due to the limitations of the app on the big size files, this process was shifted to **BigQuery**.\n\nSome files were uploaded without any problem to **BigQuery** but some failed to upload with an error. The error indicated that the type of a column was inconsistent, so I experimented by switching the auto-schema option to off and loaded the columns as strings. It helped, but then I will have to use **CAST**, **CONCAT** to clean data in the next steps.\n\n- How does it help you answer your question?\n\nThe possible patterns to reveal between the sleep, and daily activity could be useful to introduce some unique features to the current Bellabeat products, and a marketing strategy with a focus on some of those features might be useful. As a clear significance between the other brand product to Beallabeat's **Time**, I expect to find useful patterns between these two.\n\n- Are there any problems with the data?\n\nThe data is supposed to be of 30 different users, but the initial review, sorting & filtering and identifying unique user ID's show that the total user ID's vary among different data files.\n\nIt's not possible to make sure that there is no sampling bias, but again the available data should be sufficient for this study.\n\nWe have solid reasoning to believe that the data was collected and shared ethically, and privacy is protected.\n\nThis a secondary data.\n\n**Key tasks**\n\n1. Download data and store it appropriately.\n2. Identify how it’s organized.\n3. Sort and filter the data.\n4. Determine the credibility of the data.\n\n\n**Deliverable**\n\nA description of all data sources used","metadata":{}},{"cell_type":"code","source":"#Load the tidyverse\nlibrary(tidyverse)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create a dataframe named 'daily_activity' and read in one \n# of the CSV files from the dataset. Remember, you can name your dataframe \n# something different, and you can also save your CSV file under a different name as well.\n\ndaily_activity <- read_csv(\"/kaggle/input/fitbit/mturkfitbit_export_4.12.16-5.12.16/Fitabase Data 4.12.16-5.12.16/dailyActivity_merged.csv\")\n\n\n# Create another dataframe for the sleep data. \nsleep_day <- read_csv(\"/kaggle/input/fitbit/mturkfitbit_export_4.12.16-5.12.16/Fitabase Data 4.12.16-5.12.16/sleepDay_merged.csv\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#########################\n## Explore a few key tables ##\n#########################\n\n# Take a look at the daily_activity data.\n\nhead(daily_activity)\n\n\n# Identify all the columns in the daily_activity data.\ncolnames(daily_activity)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Take a look at the sleep_day data.\n\nhead(sleep_day)\n\n\n# Identify all the columns in the daily_activity data.\n\ncolnames(sleep_day)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Note that both datasets have the 'Id' field - \n# this can be used to merge the datasets.\n\n#####################################\n## Understanding some summary statistics ##\n#####################################\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# How many unique participants are there in each dataframe? \n# It looks like there may be more participants in the daily activity \n# dataset than the sleep dataset.\n\nn_distinct(daily_activity$Id)\nn_distinct(sleep_day$Id)\n\n\n# How many observations are there in each dataframe?\n\nnrow(daily_activity)\nnrow(sleep_day)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---","metadata":{}},{"cell_type":"markdown","source":"# Process.\nThen, process your data for analysis using the following Case Study Roadmap as a guide:\n\n**Case Study Roadmap - Process**\n\n**Guiding questions**\n- What tools are you choosing and why?\n- Have you ensured your data’s integrity?\n- What steps have you taken to ensure that your data is clean?\n- How can you verify that your data is clean and ready to analyze?\n- Have you documented your cleaning process so you can review and share those results?\n\n**Key tasks**\n1. Check the data for errors.\n2. Choose your tools.\n3. Transform the data so you can work with it effectively.\n4. Document the cleaning process.\n\n**Deliverable**\n\nDocumentation of any cleaning or manipulation of data\n\n**Follow these steps:**\n1. Download [the dataset.](https://www.kaggle.com/datasets/arashnic/fitbit)\n2. Unzip the files.\n3. Create a folder on your desktop or Drive to house the files. Use appropriate file-naming conventions. If you need a\nrefresher on file-naming conventions, you can revisit the [“All about file naming”](file:///C:/Users/aycad/OneDrive%20-%20Schaltbau%20Group/Masa%C3%BCst%C3%BC/OLtArwsxSlar_y35df7xmQ_634dd308c7a04d24bdfdb9367f24d5f1_Case-Study-2_-How-can-a-wellness-technology-company-play-it-smart.pdf) video or the [“Organization guidelines”](https://www.coursera.org/learn/data-preparation/supplement/fLKJI/organization-guidelines) reading.\n4. Upload the data to a tool of your choice. For a refresher on some different ways to do this, feel free to reference any of the\nfollowing resources on how to get started in the following tools (proceed to next page):\n\n| Spreadsheets | SQL | R|\n|---|---|---|\n|[Importing data from spreadsheets:](https://www.coursera.org/lecture/data-preparation/optional-importing-data-from-spreadsheets-and-databases-KCphN) This video from Course 3 will guide you through the steps you will follow to import data into your spreadsheet. This is useful if you want to perform your cleaning and analysis with spreadsheets. | [Uploading a CSV file in BigQuery:](https://scribehow.com/shared/Uploading_a_CSV_file_to_BigQuery__3qDWEO9rS6iORNQN_rBFSw)These step-by-step instructions will guide you through the process of uploading your CSV file into BigQuery so that you can start working with your data in SQL. | [Data import basics:](https://www.coursera.org/learn/data-analysis-r/supplement/qfrIM/data-import-basics) This reading from Course 7 will review importing data into R so that you can begin cleaning and analyzing it. If you are planning to use R for your case study, this is a useful starting point.|\n|[Data cleaning features in spreadsheets:](https://www.coursera.org/lecture/process-data/data-cleaning-features-in-spreadsheets-Ez3u5) This video from Course 4 outlines basic data cleaning features in spreadsheets; this is a great refresher if you need a review | [Cleaning string variables using SQL:](https://www.coursera.org/lecture/process-data/cleaning-string-variables-using-sql-xVA4Z) This video from Course 4 covers some key cleaning techniques for string data in SQL. | [Cleaning up with the basics:](https://www.coursera.org/lecture/data-analysis-r/cleaning-up-with-the-basics-3FBCt) This video from Course 7 will guide you through some basic R cleaning functions that you will need to process your data for analysis. |\n|[Even more data-cleaning techniques:](https://www.coursera.org/lecture/process-data/even-more-data-cleaning-techniques-Ei2IH) This video from Course 4 covers even more techniques you can use to clean your data and prepare it for analysis. | [Advanced data-cleaning functions part 1 and part 2:](https://www.coursera.org/lecture/process-data/advanced-data-cleaning-functions-part-1-eU2wr) These videos cover more advanced cleaning functions that are a great refresher as you begin to work more closely. | [Transforming data:](https://www.coursera.org/lecture/data-analysis-r/transforming-data-d108v) This video from Course 7 covers transforming data in R so that it is organized and formatted for easy analysis. |\n\n5. Proceed to the analyze step.\n\nIf you like, continue working with the data to better familiarize yourself and perhaps even identify new approaches to\nanswering the business questions.\n","metadata":{}},{"cell_type":"markdown","source":"**e.g.**\n\n*Process data by cleaning and checking the information.*\n\n*The group sent the survey out. Great analysts know how to respect both their data and the people who provide it. Since employees provided the data, it was important to make sure all employees gave their consent to participate. The data analysts also made sure employees understood how their data would be collected, stored, managed, and protected. Collecting and using data ethically is one of the responsibilities of data analysts. In order to maintain confidentiality and protect and store the data effectively, these were the steps they took:*\n\n*They restricted access to the data to a limited number of analysts.*\n\n*They cleaned the data to make sure it was complete, correct, and relevant. Certain data was aggregated and summarized without revealing individual responses.*\n\n*They uploaded raw data to an internal data warehouse for an additional layer of security.*","metadata":{}},{"cell_type":"markdown","source":"# Process\n\n**Guiding questions**\n- What tools are you choosing and why?\n\nAs the data is static, a data visualization tool, like **Tableau** or **Power BI**, was not preferred but instead **R** will be used for the analysis and for the visualization to present along with the high-level recommendations expected at the end, for the Bellabeat's marketing strategy.\n\nR will also be useful to keep records, while an R Markdown file has already been structured around the 6 phases of the data analysis process, to later present the findings and the thinking process in a convenient way.\n\nUploading a clean final version to **Kaggle** is planned share the results and t  be able to get community feedback.\n\n- Have you ensured your data’s integrity?\n- What steps have you taken to ensure that your data is clean?\n- How can you verify that your data is clean and ready to analyze?\n- Have you documented your cleaning process so you can review and share those results?\n\n**Key tasks**\n1. Check the data for errors.\n2. Choose your tools.\n3. Transform the data so you can work with it effectively.\n4. Document the cleaning process.\n\n**Deliverable**\n\nDocumentation of any cleaning or manipulation of data","metadata":{}},{"cell_type":"code","source":"# What are some quick summary statistics we'd want to know about each data frame?\n  \n# For the daily activity dataframe:\ndaily_activity %>%  \n  select(TotalSteps,\n         TotalDistance,\n         SedentaryMinutes) %>%\n  summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# For the sleep dataframe:\n\nsleep_day %>%  \n  select(TotalSleepRecords,\n         TotalMinutesAsleep,\n         TotalTimeInBed) %>%\n  summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# What does this tell us about how this sample of people's activities? \n\n##########################\n## Plotting a few explorations ##\n##########################\n\n# What's the relationship between steps taken in a day and sedentary minutes? \n# How could this help inform the customer segments that we can market to? \n# E.g. position this more as a way to get started in walking more? \n# Or to measure steps that you're already taking?\n\nggplot(data=daily_activity, aes(x=TotalSteps, y=SedentaryMinutes)) + geom_point()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# What's the relationship between minutes asleep and time in bed? \n# You might expect it to be almost completely linear - are there any unexpected trends?\n  \n\nggplot(data=sleep_day, aes(x=TotalMinutesAsleep, y=TotalTimeInBed)) + geom_point()\n\n\n# What could these trends tell you about how to help market this product? Or areas where you might want to explore further?","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##################################\n## Merging these two datasets together ##\n##################################\n  \ncombined_data <- merge(sleep_day, daily_activity, by=\"Id\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Take a look at how many participants are in this data set.\n\nn_distinct(combined_data$Id)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# mine \nView(combined_data)\ncor(combined_data$TotalSteps, combined_data$TotalMinutesAsleep)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# mine \nmeanSleep <- combined_data %>% \n  group_by(Id) %>% \n  drop_na %>% \n  summarize(MeanMinutesAsleep = mean(TotalMinutesAsleep))\n\nView(meanSleep)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# mine \nbed <- sleep_day %>%\n  group_by(SleepDay) %>%\n  summarize(mean(TotalTimeInBed), sd(TotalTimeInBed), mean (TotalMinutesAsleep), sd(TotalMinutesAsleep), cor(TotalTimeInBed, TotalMinutesAsleep))\n\nView(bed)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---","metadata":{}},{"cell_type":"markdown","source":"# Analyze.\nNow that your data is stored appropriately and has been prepared for analysis, start putting it to work. Use the following Case\nStudy Roadmap as a guide:\n\n**Case Study Roadmap - Analyze**\n\n**Guiding questions**\n- How should you organize your data to perform analysis on it?\n- Has your data been properly formatted?\n- What surprises did you discover in the data?\n- What trends or relationships did you find in the data?\n- How will these insights help answer your business questions?\n\n**Key tasks**\n1. Aggregate your data so it’s useful and accessible.\n2. Organize and format your data.\n3. Perform calculations.\n4. Identify trends and relationships.\n\n**Deliverable**\n\nA summary of your analysis\n\n**Follow these steps for using SQL**\n\nHere is a sample script that can help you do the following:\nTo use the sample script, [click this link](https://docs.google.com/document/d/1gWsf3gW4oKDbOD2MwFGZqzz_HAsOR4T9EQ-b1i40s58/template/preview) and select “Use Template.”\n1. Import your data.\n2. Explore your data, perhaps looking at the total number of rows, distinct values, maximum, minimum, or mean values. 3.\nWhere relevant, use JOIN statements to combine your relevant data into different tables based upon the needs of your\nanalyses.\n4. Create summary statistics.\n5. Investigate interesting trends and save that information to a table.\n\n**To get started in R**\n\nOpen your preferred version of R, click [this link](https://docs.google.com/document/d/1gmPCr0zqjOtVK_y_BKsaUItBJHakw9ghB4x7dZYVvvo/template/preview), and select “Use template.” Then, copy and paste the text from the template into\nan R script.\n1. Begin importing your data.\n2. Explore your data, gathering some summary statistics\n3. Clean and transform your data to prepare for analysis\n4. Create some initial exploratory visualizations\n","metadata":{}},{"cell_type":"markdown","source":"**e.g.**\n\n*Analyze data to find patterns, relationships, and trends.*\n\n*Then, the analysts did what they do best: analyze! From the completed surveys, the data analysts discovered that an employee’s experience with certain processes was a key indicator of overall job satisfaction. These were their findings:*\n\n*Employees who experienced a long and complicated hiring process were most likely to leave the company.*\n\n*Employees who experienced an efficient and transparent evaluation and feedback process were most likely to remain with the company.*\n\n*The group knew it was important to document exactly what they found in the analysis, no matter what the results. To do otherwise would diminish trust in the survey process and reduce their ability to collect truthful data from employees in the future.*","metadata":{}},{"cell_type":"markdown","source":"# Analyze\n\netc. etc.","metadata":{}},{"cell_type":"code","source":"# mine\nggplot(data = combined_data, aes(x = TotalTimeInBed, y = TotalMinutesAsleep)) + \n  geom_point() +\n  geom_smooth(method=\"gam\", \n              formula = y ~s(x))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Note that there were more participant Ids in the daily activity \n# dataset that have been filtered out using merge. Consider using 'outer_join' \n# to keep those in the dataset. \n\n# Now you can explore some different relationships between activity and sleep as well. \n# For example, do you think participants who sleep more also take more steps or fewer \n# steps per day? Is there a relationship at all? How could these answers help inform \n# the marketing strategy of how you position this new product?\n  \n# This is just one example of how to get started with this data - there are many other \n# files and questions to explore as well!\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---","metadata":{}},{"cell_type":"markdown","source":"# Share.\nOnce you have completed your analysis, create your data visualizations. The visualizations should clearly communicate your\nhigh-level insights and recommendations. Use the following Case Study Roadmap as a guide:\n\n**Case Study Roadmap - Share**\n\n**Guiding questions**\n- Were you able to answer the business questions?\n- What story does your data tell?\n- How do your findings relate to your original question?\n- Who is your audience? What is the best way to communicate with them?\n- Can data visualization help you share your findings?\n- Is your presentation accessible to your audience?\n\n**Key tasks**\n1. Determine the best way to share your findings\n2. Create effective data visualizations\n3. Present your findings\n4. Ensure your work is accessible.\n\n**Deliverable**\n\nSupporting visualizations and key findings\n\n**Follow these steps:**\n1. Take out a piece of paper and a pen and sketch some ideas for how you will visualize the data. \n2. Once you choose a visual form, open your tool of choice to create your visualization. Use a presentation software, such as PowerPoint or Google Slides; your spreadsheet program; Tableau; or R.\n3. Create your data visualization, remembering that contrast should be used to draw your audience’s attention to the most important insights. Use artistic principles including size, color, and shape.\n4. Ensure clear meaning through the proper use of common elements, such as headlines, subtitles, and labels. \n5. Refine your data visualization by applying deep attention to detail.","metadata":{}},{"cell_type":"markdown","source":"**e.g.**\n\n*Share data with your audience.*\n\n*Just as they made sure the data was carefully protected, the analysts were also careful sharing the report. This is how they shared their findings:*\n\n*They shared the report with managers who met or exceeded the minimum number of direct reports with submitted responses to the survey.*\n\n*They presented the results to the managers to make sure they had the full picture.*\n\n*They asked the managers to personally deliver the results to their teams.*\n\n*This process gave managers an opportunity to communicate the results with the right context. As a result, they could have productive team conversations about next steps to improve employee engagement.*","metadata":{}},{"cell_type":"markdown","source":"# Share\n\netc. etc.","metadata":{}},{"cell_type":"markdown","source":"---","metadata":{}},{"cell_type":"markdown","source":"# Act.\nNow that you have finished creating your visualizations, act on your findings. Prepare the deliverables you have been asked to\ncreate, including the high-level recommendations based on your analysis. Use the following Case Study Roadmap as a guide:\n\n**Case Study Roadmap - Act**\n\n**Guiding questions**\n- What is your final conclusion based on your analysis?\n- How could your team and business apply your insights?\n- What next steps would you or your stakeholders take based on your findings?\n- Is there additional data you could use to expand on your findings?\n\n**Key tasks**\n- Create your portfolio\n- Add your case study\n- Practice presenting your case study to a friend or family member\n\n**Deliverable**\n\nYour top high-level insights based on your analysis\n\n**Follow these steps:**\n1. If you do not have one already, create an online portfolio. (Use [Build a Portfolio with Google Sites](https://applieddigitalskills.withgoogle.com/c/middle-and-high-school/en/build-a-portfolio-with-google-sites/build-a-portfolio-with-google-sites/introduction-to-build-a-portfolio-with-google-sites.html).)\n2. Consider how you want to feature your case study in your portfolio.\n3. Upload or link your case study findings to your portfolio.\n4. Write a brief paragraph describing the case study, your process, and your discoveries.\n5. Add the paragraph to introduce your case study in your portfolio.\n","metadata":{}},{"cell_type":"markdown","source":"**e.g.**\n\n*Act on the data and use the analysis results.*\n\n*The last stage of the process for the team of analysts was to work with leaders within their company and decide how best to implement changes and take actions based on the findings. These were their recommendations:*\n\n*Standardize the hiring and evaluation process for employees based on the most efficient and transparent practices.*\n\n*Conduct the same survey annually and compare results with those from the previous year.*","metadata":{}},{"cell_type":"markdown","source":"# Act\n\netc. etc.","metadata":{}},{"cell_type":"markdown","source":"---","metadata":{}},{"cell_type":"markdown","source":"# Wrap-up.\nCongratulations on finishing the Bellabeat marketing analysis case study! If you like, complete one of the other case studies to\ncontinue growing your portfolio. Or, use the steps from the ask, prepare, process, analyze, share, and act Case Study\nRoadmap to create a new project all your own. Best of luck on your job search","metadata":{}},{"cell_type":"markdown","source":"# Appendix\n\n**My workflow & tools:**\n\n*I planned to use R from the start, as it would make it possible both to show my thinking process step by step and to get a deliverable in the end. I also wanted to dive deeper into R, but decided to start with some familiar tools first.*\n\n*I didn't consider using **Tableau** or **Power BI**, as the data is static in this case and also most of the data that I will be working on in the future.*\n\n*As an initial start, I wanted to review the data using some tools I have previous familiarity with, e.g. **Excel** and **Power Query**.*\n\n- **Excel**: *I started to skim the small size CSV files initially with Excel, but it was already obvious that spreadsheets software wouldn't be sufficient.* \n- **Power Query**: *So, I switched to Power Query assuming that I would be able to transform the data and link the query to Excel, to have a light-weight file to be able to do some sorting and filtering. It didn't go as planned, due to the file sizes. - \n- **Access**: *I tried using Access, which I have no prior experience with, and it worked up to some degree. But I decided to switch to BigQuery to be able to use SQL.*\n- **BigQuery**: \n- **Connected Sheets**: \n- **Google Sheets**: \n- **posit.cloud**: *I simply didn't find it much convenient to work on posit.cloud, so I rapidly switched to RStudio on my desktop.*  \n- **RStudio**: *I used*\n- **Kaggle**: \n- **Anaconda**: \n- **Docker**: \n\n**Lessons learned**\\\netc. etc.\n","metadata":{}},{"cell_type":"markdown","source":"---","metadata":{}}]}